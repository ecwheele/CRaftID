{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Install InstructionsÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If using anaconda (recommended), install the following packages\n",
    "conda install -c conda-forge opencv\n",
    "\n",
    "conda install -c conda-forge tqdm\n",
    "\n",
    "conda install -c anaconda scikit-learn\n",
    "\n",
    "### IF USING GPUs:\n",
    "conda install -c anaconda keras-gpu\n",
    "\n",
    "### IF USING CPU only:\n",
    "conda install -c anaconda keras\n",
    "\n",
    "\n",
    "## If using pip, install the following packages\n",
    "\n",
    "pip install opencv-python\n",
    "\n",
    "pip install tqdm\n",
    "\n",
    "pip install -U scikit-learn\n",
    "\n",
    "### IF USING GPUs:\n",
    "pip install tensorflow-gpu\n",
    "\n",
    "### IF USING CPU only:\n",
    "pip install tensorflow\n",
    "\n",
    "pip install Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Deploy the model and classify CellRaft images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how to deploy our model (or your own equivalent model), follow along the notebook titled \"Implementation of Classifiers\". This notebook runs through a few example images hosted on this repo, returning their predicted classification. However, when running through the entire dataset of CellRaft images, we used a script with the same code to run in the background.\n",
    "\n",
    "### Note:\n",
    "\n",
    "While training the models is best done on GPU instances, this is not necessary for deploying the model. To save on data storage costs, you can deploy and run the model on the computer/compute-cluster hosting your full CellRaft dataset as long as the necessary dependencies can be installed on the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Train your own model or transfer learn from ours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder with directories inside for each class. Manually curate your training dataset and keep images in these folders as per their assigned class. Set aside 20% of images in each class for downstream testing of your model. If using limited numbers of training data, you can augment the size of the training dataset by flipping, rotating, and adjusting brightness/contrast of images. \n",
    "\n",
    "Follow along the notebook titled \"Training the classifiers\". Please note that this notebook is meant as a guide. You will have to supply your own training data as our training data is not yet hosted.\n",
    "\n",
    "To use transfer learning to further train our pre-trained model for your specific cell lines/phenotypes, follow along this nifty article for the adjustments you would need to make to our code: https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e\n",
    "\n",
    "### Note:\n",
    "We recommend using computing resources with GPU instances to train the model in a time effective manner. We used NVIDIA P6000 instances available on Paperspace, a cloud computing provider. However, it is possible to train and deploy these models on CPU based instances or even on any modern laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
