{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "UsageError: Line magic function `%matplotlib.inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from random import sample\n",
    "from random import choice\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib.inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifiers on curated training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter paths to your training data. In our training, to increase training samples and to achieve class balance when training one vs. all classifiers, we created two seperate folders for each class: 1) original files without any augmentation and 2) files augmented so that the number of augmented images in the training class approximately equals the number of un-augmented images in all other classes combined\n",
    "\n",
    "## PLEASE NOTE:\n",
    "This notebook is meant to be modified to be used with the user's own training data. Training data is not hosted on this Github repository and hence this notebook will not work without supplied training data. This notebook is a guide on how to train a model as we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_data_dir = '/notebooks/storage/master_trainingSet/balanced'\n",
    "notaug_train_data_dir = '/notebooks/storage/master_trainingSet/'\n",
    "test_data_dir = '/notebooks/storage/master_trainingSet/vallidation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all classes being trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = ['artifacts_A','artifacts_B','lysed','outFocus','bad_dense']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that returns a vector label for an image. If a training image is in the training class, it returns [1,0], otherwise it returns [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(given_class,train_class):\n",
    "    if given_class == train_class:\n",
    "        vec = [1,0]\n",
    "    else:\n",
    "        vec = [0,1]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to load all training data with proper labels before training each one vs. all classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(train_class):\n",
    "\n",
    "    train_images = []\n",
    "    # load augmented in class data\n",
    "    file_dir = aug_train_data_dir+'/'+train_class+'aug'\n",
    "    for cl in train_classes:\n",
    "        file_dir = aug_train_data_dir + '/' + cl + 'aug'\n",
    "        for i in os.listdir(file_dir):\n",
    "            path = os.path.join(file_dir,i)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            try:\n",
    "                img = cv2.resize(img, (64,64))\n",
    "            except:\n",
    "                continue\n",
    "            train_images.append([np.array(img).reshape(-1,64,64,1), label(cl,train_class)])\n",
    "                \n",
    "    shuffle(train_images)\n",
    "    \n",
    "    return  train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a gridsearch (implemented via scikit-learn package) to optimize hyperparameters for each one vs. all classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {'artifacts_A': ['categorical_crossentropy', 0.3, 'Adam'],\n",
    " 'artifacts_B': ['categorical_crossentropy', 0.1, 'Adam'],\n",
    " 'lysed': ['logcosh', 0.3, 'Adam'],\n",
    " 'outFocus': ['categorical_crossentropy', 0.3, 'Adam'],\n",
    " 'bad_dense': ['categorical_crossentropy', 0.25, 'Adam']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training on GPUs with batches, if training data isn't equally divided into each batch (i.e. one batch has fewer images than the rest), you will see a sudden spike in training loss. While the effects of this are negated after a few epochs of training, you can achieve cleaner training by ensuring that each batch has the same number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_batch_size(tr_set_size):\n",
    "    # make list of factors\n",
    "    factors = []\n",
    "    for i in range(1, tr_set_size + 1):\n",
    "        if tr_set_size % i ==0:\n",
    "            factors.append(i)\n",
    "    possible_batches = list(filter(lambda a: a > 20, factors))\n",
    "    return possible_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model in Keras. Here we use three consecutive convolutional + maxpooling layers, followed by a densely connected layer and a final 2 neuron layer (2 neurons for binary classification). If you wish to use transfer learning to use our models as a starting point but train it further to specialize on your desired cell line/phenotype. To make adjustments to the code below for transfer learning, see this article for a useful introduction to transfer learning using Keras: https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val,params,train_class):\n",
    "    \n",
    "    #########\n",
    "    #\n",
    "    # ENTER THE PATH WHERE YOU WANT TO SAVE YOUR MODELS HERE:\n",
    "    #########\n",
    "    \n",
    "    model_save_dir = '/notebooks/storage/hierarchical_files/models/'\n",
    "    \n",
    "    # find batch size\n",
    "    found = False\n",
    "    while found == False:\n",
    "        batch_size = find_batch_size(len(x_train))[0]\n",
    "        if batch_size < 100:\n",
    "            found = True\n",
    "        else:\n",
    "            x_train = x_train[:-1]\n",
    "            y_train = y_train[:-1]\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(input_shape=[64,64,1]))\n",
    "    model.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=5,padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=50,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=5,padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=80,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=5,padding='same'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    # Changing to 2 nuerons to reflect 2 classes\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    optimizer = Adam(lr=0.000001)\n",
    "\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    #####\n",
    "    #\n",
    "    # IF USING TENSORBOARD, CHANGE DIRECTORY AND NAME AS YOU'D PREFER:\n",
    "    ####\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir='/notebooks/storage/tensorboard_logs/'+train_class+\"attemptX{}\".format(time()),histogram_freq=0,write_graph=True, write_images=True)\n",
    "    model.fit(x=x_train,y=y_train,\n",
    "              epochs=10000,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=[x_val,y_val],\n",
    "              verbose=0,\n",
    "              callbacks=[tensorboard])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_save_dir + train_class+\"_model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_save_dir + train_class+\"_weights.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "    \n",
    "    return model\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training each one vs. all classifier. We trained our models on a P6000 GPU instance on Paperspace overnight (each model takes ~1-1.5 hours). If you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fbd50aaeb3416ba1fbaa9afab26208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 183,460\n",
      "Trainable params: 183,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 183,460\n",
      "Trainable params: 183,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 183,460\n",
      "Trainable params: 183,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 183,460\n",
      "Trainable params: 183,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 183,460\n",
      "Trainable params: 183,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 183,460\n",
      "Trainable params: 183,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 64, 64, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 13, 13, 50)        40050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 3, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 3, 3, 80)          100080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1, 1, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               41472     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 183,460\n",
      "Trainable params: 183,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# train one v all classifiers\n",
    "model_dict = {}\n",
    "for cl in tqdm(train_classes):\n",
    "    training_images = train_data(cl)\n",
    "    X = np.array([i[0] for i in training_images]).reshape(-1,64,64,1)\n",
    "    Y = np.array([i[1] for i in training_images])\n",
    "    # create train/validation split (12.5% of train images are validation)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.125, shuffle= True)\n",
    "    params = training_params[cl]\n",
    "    model_ = train_model(x_train,y_train,x_valid,y_valid,params,cl)\n",
    "    model_dict[cl] = model_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
